{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83fbf6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow\n",
    "import tensorflow.keras as keras\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D,BatchNormalization\n",
    "from keras.constraints import maxnorm\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d71f97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [DO NOT MODIFY THIS CELL]\n",
    "\n",
    "# load the images\n",
    "n_img = 50000\n",
    "n_noisy = 40000\n",
    "n_clean_noisy = n_img - n_noisy\n",
    "imgs = np.empty((n_img,32,32,3))\n",
    "for i in range(n_img):\n",
    "    img_fn = f'../data/images/{i+1:05d}.png'\n",
    "    imgs[i,:,:,:]=cv2.cvtColor(cv2.imread(img_fn),cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# load the labels\n",
    "clean_labels = np.genfromtxt('../data/clean_labels.csv', delimiter=',', dtype=\"int8\")\n",
    "noisy_labels = np.genfromtxt('../data/noisy_labels.csv', delimiter=',', dtype=\"int8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5d0449",
   "metadata": {},
   "source": [
    "### 2.2. Model I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5706d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_valid_test split\n",
    "imgs_train, imgs_test, labels_train, labels_test  = train_test_split(imgs, noisy_labels, test_size=0.2, random_state=7)\n",
    "imgs_train, imgs_valid, labels_train, labels_valid  = train_test_split(imgs_train, labels_train, test_size=0.25, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bb5d420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize x\n",
    "X_train = np.array(imgs_train) / 255\n",
    "X_valid = np.array(imgs_valid) / 255\n",
    "X_test = np.array(imgs_test) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7273a674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN\n",
    "def model_I(image):\n",
    "    '''\n",
    "    This function should takes in the image of dimension 32*32*3 as input and returns a label prediction\n",
    "    '''\n",
    "    #create model\n",
    "    model = Sequential()\n",
    "    #add model layers\n",
    "    model.add(Conv2D(32, (3,3), padding=\"same\", activation=\"relu\", input_shape=(32, 32, 3)))\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    model.add(Conv2D(64, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    model.add(Conv2D(64, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(Dense(10))\n",
    "    #compile model using accuracy to measure model performance\n",
    "    model.compile(optimizer='adam', loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "    #train the model\n",
    "    history = model.fit(X_train, labels_train, epochs=10, validation_data=(X_valid, labels_valid))\n",
    "    #predict\n",
    "    X_test = np.array(image)/255\n",
    "    label=np.argmax(model.predict(X_test),axis=1)\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2049da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "938/938 [==============================] - 29s 31ms/step - loss: 2.2814 - accuracy: 0.1375 - val_loss: 2.2589 - val_accuracy: 0.1728\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 29s 31ms/step - loss: 2.2492 - accuracy: 0.1806 - val_loss: 2.2519 - val_accuracy: 0.1812\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 28s 30ms/step - loss: 2.2261 - accuracy: 0.2029 - val_loss: 2.2375 - val_accuracy: 0.1941\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 28s 30ms/step - loss: 2.1998 - accuracy: 0.2215 - val_loss: 2.2375 - val_accuracy: 0.2043\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 27s 29ms/step - loss: 2.1709 - accuracy: 0.2378 - val_loss: 2.2363 - val_accuracy: 0.2129\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 28s 30ms/step - loss: 2.1302 - accuracy: 0.2575 - val_loss: 2.2455 - val_accuracy: 0.2142\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 28s 30ms/step - loss: 2.0706 - accuracy: 0.2802 - val_loss: 2.2757 - val_accuracy: 0.2116\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 28s 30ms/step - loss: 1.9901 - accuracy: 0.3108 - val_loss: 2.3383 - val_accuracy: 0.2037\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 28s 30ms/step - loss: 1.8924 - accuracy: 0.3461 - val_loss: 2.4580 - val_accuracy: 0.1893\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 28s 30ms/step - loss: 1.7723 - accuracy: 0.3909 - val_loss: 2.5964 - val_accuracy: 0.1870\n",
      "Time:  287.456844 seconds\n"
     ]
    }
   ],
   "source": [
    "# test for CNN (less than 10 min)\n",
    "start = timeit.default_timer()\n",
    "labels_pred = model_I(imgs_test)\n",
    "stop = timeit.default_timer()\n",
    "print('Time: ', stop - start, 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b37db4",
   "metadata": {},
   "source": [
    "### 2.3. Model II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44608e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_II(image):\n",
    "    #create model\n",
    "    model = Sequential()\n",
    "    #add model layers\n",
    "    model.add(Conv2D(32, (3,3), padding=\"same\", activation=\"relu\", input_shape=(32, 32, 3)))\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    model.add(Conv2D(64, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    model.add(Conv2D(64, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Flatten())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(Dense(10))\n",
    "    #compile model using accuracy to measure model performance\n",
    "    model.compile(optimizer='adam', loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "    #train the model\n",
    "    history = model.fit(X_train_2, labels_train, epochs=10, validation_data=(X_valid_2, labels_valid))\n",
    "    #predict\n",
    "    X_test = np.array(image)/255    \n",
    "    label = model.predict(X_test)\n",
    "    model.save('model.h5')\n",
    "    label = np.argmax(np.round(label), axis=1)\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0e2bd2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "188/188 [==============================] - 7s 35ms/step - loss: 1.7151 - accuracy: 0.3933 - val_loss: 2.1733 - val_accuracy: 0.1495\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 8s 42ms/step - loss: 1.3014 - accuracy: 0.5355 - val_loss: 2.0547 - val_accuracy: 0.2540\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 8s 40ms/step - loss: 1.0933 - accuracy: 0.6173 - val_loss: 1.4151 - val_accuracy: 0.5005\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 8s 40ms/step - loss: 0.9138 - accuracy: 0.6767 - val_loss: 1.2955 - val_accuracy: 0.5300\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 7s 39ms/step - loss: 0.7720 - accuracy: 0.7218 - val_loss: 2.9444 - val_accuracy: 0.3380\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 6s 34ms/step - loss: 0.6272 - accuracy: 0.7763 - val_loss: 1.5763 - val_accuracy: 0.5300\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 6s 30ms/step - loss: 0.4926 - accuracy: 0.8328 - val_loss: 1.7548 - val_accuracy: 0.5310\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 6s 31ms/step - loss: 0.3878 - accuracy: 0.8667 - val_loss: 1.9077 - val_accuracy: 0.5315\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 6s 31ms/step - loss: 0.3202 - accuracy: 0.8887 - val_loss: 1.8717 - val_accuracy: 0.5360\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 6s 31ms/step - loss: 0.2366 - accuracy: 0.9258 - val_loss: 2.0136 - val_accuracy: 0.5365\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "# train CNN using clean labels\n",
    "imgs_train_2, imgs_test_2, labels_train, labels_test  = train_test_split(imgs[0:10000], clean_labels, test_size=0.2, random_state=7)\n",
    "imgs_train_2, imgs_valid_2, labels_train, labels_valid  = train_test_split(imgs_train_2, labels_train, test_size=0.25, random_state=7)\n",
    "# Normalize x\n",
    "X_train_2 = np.array(imgs_train_2) / 255\n",
    "X_valid_2 = np.array(imgs_valid_2) / 255\n",
    "X_test_2 = np.array(imgs_test_2) / 255\n",
    "label_pred1=model_II(imgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a43fcb1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "364/364 [==============================] - 13s 35ms/step - loss: 1.4448 - accuracy: 0.4957 - val_loss: 1.7846 - val_accuracy: 0.3877\n",
      "Epoch 2/10\n",
      "364/364 [==============================] - 14s 38ms/step - loss: 1.0544 - accuracy: 0.6368 - val_loss: 2.5512 - val_accuracy: 0.3318\n",
      "Epoch 3/10\n",
      "364/364 [==============================] - 11s 30ms/step - loss: 0.8832 - accuracy: 0.6945 - val_loss: 1.9086 - val_accuracy: 0.4699\n",
      "Epoch 4/10\n",
      "364/364 [==============================] - 14s 38ms/step - loss: 0.7543 - accuracy: 0.7365 - val_loss: 1.1065 - val_accuracy: 0.6347\n",
      "Epoch 5/10\n",
      "364/364 [==============================] - 15s 40ms/step - loss: 0.6389 - accuracy: 0.7766 - val_loss: 1.6855 - val_accuracy: 0.5397\n",
      "Epoch 6/10\n",
      "364/364 [==============================] - 15s 41ms/step - loss: 0.5496 - accuracy: 0.8067 - val_loss: 1.4082 - val_accuracy: 0.6059\n",
      "Epoch 7/10\n",
      "364/364 [==============================] - 12s 34ms/step - loss: 0.4698 - accuracy: 0.8348 - val_loss: 1.1886 - val_accuracy: 0.6584\n",
      "Epoch 8/10\n",
      "364/364 [==============================] - 15s 41ms/step - loss: 0.4056 - accuracy: 0.8594 - val_loss: 1.3167 - val_accuracy: 0.6440\n",
      "Epoch 9/10\n",
      "364/364 [==============================] - 15s 42ms/step - loss: 0.3194 - accuracy: 0.8907 - val_loss: 1.6024 - val_accuracy: 0.6118\n",
      "Epoch 10/10\n",
      "364/364 [==============================] - 14s 38ms/step - loss: 0.2741 - accuracy: 0.9053 - val_loss: 1.3780 - val_accuracy: 0.6476\n",
      "The accuracy of the cnn is:0.650696\n"
     ]
    }
   ],
   "source": [
    "new_clean_idx=np.append(range(10000),np.array(range(10000,50000))[label_pred1[10000:]==noisy_labels[10000:]])\n",
    "new_clean_labels=np.append(clean_labels,noisy_labels[new_clean_idx[10000:]])\n",
    "new_clean_imgs=imgs[new_clean_idx]\n",
    "\n",
    "# train CNN using clean labels\n",
    "imgs_train_2, imgs_test_2, labels_train, labels_test  = train_test_split(new_clean_imgs, new_clean_labels, test_size=0.2, random_state=7)\n",
    "imgs_train_2, imgs_valid_2, labels_train, labels_valid  = train_test_split(imgs_train_2, labels_train, test_size=0.25, random_state=7)\n",
    "# Normalize x\n",
    "X_train_2 = np.array(imgs_train_2) / 255\n",
    "X_valid_2 = np.array(imgs_valid_2) / 255\n",
    "X_test_2 = np.array(imgs_test_2) / 255\n",
    "label_pred2=model_II(imgs_test_2)\n",
    "\n",
    "acc=np.mean(label_pred2==labels_test)\n",
    "print('The accuracy of the cnn is:%3f'%(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0723bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  231.65833219999996 seconds\n"
     ]
    }
   ],
   "source": [
    "stop = timeit.default_timer()\n",
    "print('Time: ', stop - start, 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d82f5be",
   "metadata": {},
   "source": [
    "## 3. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d46ec73",
   "metadata": {},
   "source": [
    "For assessment, we will evaluate your final model on a hidden test dataset with clean labels by the `evaluation` function defined as follows. Although you will not have the access to the test set, the function would be useful for the model developments. For example, you can split the small training set, using one portion for weakly supervised learning and the other for validation purpose. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3066abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [DO NOT MODIFY THIS CELL]\n",
    "def evaluation(model, test_labels, test_imgs):\n",
    "    y_true = test_labels\n",
    "    y_pred = []\n",
    "    for image in test_imgs:\n",
    "        y_pred.append(model(image))\n",
    "    print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "622e10cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "../data/test_labels.csv not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-82821a72951b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Nonetheless, you can create your own validation set to run the evlauation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mn_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtest_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenfromtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../data/test_labels.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"int8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mtest_imgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mgenfromtxt\u001b[1;34m(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise, max_rows, encoding, like)\u001b[0m\n\u001b[0;32m   1789\u001b[0m             \u001b[0mfname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1790\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1791\u001b[1;33m             \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1792\u001b[0m             \u001b[0mfid_ctx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclosing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1793\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\numpy\\lib\\_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m     \u001b[0mds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\numpy\\lib\\_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[0;32m    529\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[0;32m    530\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s not found.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: ../data/test_labels.csv not found."
     ]
    }
   ],
   "source": [
    "# [DO NOT MODIFY THIS CELL]\n",
    "# This is the code for evaluating the prediction performance on a testset\n",
    "# You will get an error if running this cell, as you do not have the testset\n",
    "# Nonetheless, you can create your own validation set to run the evlauation\n",
    "n_test = 10000\n",
    "test_labels = np.genfromtxt('../data/test_labels.csv', delimiter=',', dtype=\"int8\")\n",
    "test_imgs = np.empty((n_test,32,32,3))\n",
    "for i in range(n_test):\n",
    "    img_fn = f'../data/test_images/test{i+1:05d}.png'\n",
    "    test_imgs[i,:,:,:]=cv2.cvtColor(cv2.imread(img_fn),cv2.COLOR_BGR2RGB)\n",
    "evaluation(baseline_model, test_labels, test_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a84fc0",
   "metadata": {},
   "source": [
    "The overall accuracy is $0.24$, which is better than random guess (which should have a accuracy around $0.10$). For the project, you should try to improve the performance by the following strategies:\n",
    "\n",
    "- Consider a better choice of model architectures, hyperparameters, or training scheme for the predictive model;\n",
    "- Use both `clean_noisy_trainset` and `noisy_trainset` for model training via **weakly supervised learning** methods. One possible solution is to train a \"label-correction\" model using the former, correct the labels in the latter, and train the final predictive model using the corrected dataset.\n",
    "- Apply techniques such as $k$-fold cross validation to avoid overfitting;\n",
    "- Any other reasonable strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9bf1136",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-47e4c13b6f1e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_timer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mevaluation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_imgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'test_labels' is not defined"
     ]
    }
   ],
   "source": [
    "#Evaluation of model II\n",
    "start = timeit.default_timer()\n",
    "model=keras.models.load_model('model.h5')\n",
    "evaluation(model, test_labels, test_imgs)\n",
    "stop = timeit.default_timer()\n",
    "print('Time: ', stop - start, 'seconds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
