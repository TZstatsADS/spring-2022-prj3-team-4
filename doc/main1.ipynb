{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83fbf6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow\n",
    "import tensorflow.keras as keras\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n",
    "from keras.constraints import maxnorm\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d71f97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [DO NOT MODIFY THIS CELL]\n",
    "\n",
    "# load the images\n",
    "n_img = 50000\n",
    "n_noisy = 40000\n",
    "n_clean_noisy = n_img - n_noisy\n",
    "imgs = np.empty((n_img,32,32,3))\n",
    "for i in range(n_img):\n",
    "    img_fn = f'../data/images/{i+1:05d}.png'\n",
    "    imgs[i,:,:,:]=cv2.cvtColor(cv2.imread(img_fn),cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# load the labels\n",
    "clean_labels = np.genfromtxt('../data/clean_labels.csv', delimiter=',', dtype=\"int8\")\n",
    "noisy_labels = np.genfromtxt('../data/noisy_labels.csv', delimiter=',', dtype=\"int8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5d0449",
   "metadata": {},
   "source": [
    "### 2.2. Model I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5706d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_valid_test split\n",
    "imgs_train, imgs_test, labels_train, labels_test  = train_test_split(imgs, noisy_labels, test_size=0.2, random_state=50)\n",
    "imgs_train, imgs_valid, labels_train, labels_valid  = train_test_split(imgs_train, labels_train, test_size=0.25, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bb5d420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize x\n",
    "X_train = np.array(imgs_train) / 255\n",
    "X_valid = np.array(imgs_valid) / 255\n",
    "X_test = np.array(imgs_test) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7273a674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN\n",
    "def model_I(image):\n",
    "    '''\n",
    "    This function should takes in the image of dimension 32*32*3 as input and returns a label prediction\n",
    "    '''\n",
    "    #create model\n",
    "    model = Sequential()\n",
    "    #add model layers\n",
    "    model.add(Conv2D(32, (3,3), padding=\"same\", activation=\"relu\", input_shape=(32, 32, 3)))\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    model.add(Conv2D(64, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    model.add(Conv2D(64, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(Dense(10))\n",
    "    #compile model using accuracy to measure model performance\n",
    "    model.compile(optimizer='adam', loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "    #train the model\n",
    "    history = model.fit(X_train, labels_train, epochs=10, validation_data=(X_valid, labels_valid))\n",
    "    #predict\n",
    "    X_test = np.array(image)/255\n",
    "    return np.round(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f2d1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #compile model using accuracy to measure model performance\n",
    "    model.compile(optimizer='adam', loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "    #train the model\n",
    "    history = model.fit(X_train_2, labels_train, epochs=10)\n",
    "    #predict\n",
    "    X_test = np.array(image)/255    \n",
    "    label = model.predict(X_test)\n",
    "    model.save('model2.h5')\n",
    "    label = np.argmax(np.round(label), axis=1)\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2049da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "938/938 [==============================] - 52s 54ms/step - loss: 2.2808 - accuracy: 0.1432 - val_loss: 2.2554 - val_accuracy: 0.1793\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 49s 52ms/step - loss: 2.2400 - accuracy: 0.1917 - val_loss: 2.2377 - val_accuracy: 0.1944\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 55s 58ms/step - loss: 2.2153 - accuracy: 0.2132 - val_loss: 2.2233 - val_accuracy: 0.2104\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 55s 58ms/step - loss: 2.1962 - accuracy: 0.2250 - val_loss: 2.2237 - val_accuracy: 0.2196\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 52s 56ms/step - loss: 2.1715 - accuracy: 0.2401 - val_loss: 2.2275 - val_accuracy: 0.2214\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 54s 57ms/step - loss: 2.1402 - accuracy: 0.2569 - val_loss: 2.2339 - val_accuracy: 0.2183\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 45s 48ms/step - loss: 2.0970 - accuracy: 0.2760 - val_loss: 2.2765 - val_accuracy: 0.2115\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 46s 49ms/step - loss: 2.0347 - accuracy: 0.2988 - val_loss: 2.3162 - val_accuracy: 0.2069\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 48s 51ms/step - loss: 1.9554 - accuracy: 0.3269 - val_loss: 2.3516 - val_accuracy: 0.2010\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 47s 51ms/step - loss: 1.8581 - accuracy: 0.3580 - val_loss: 2.4470 - val_accuracy: 0.2029\n",
      "Time:  511.7168006999999 seconds\n"
     ]
    }
   ],
   "source": [
    "# test for CNN (less than 10 min)\n",
    "start = timeit.default_timer()\n",
    "history = model_I(imgs_test)\n",
    "stop = timeit.default_timer()\n",
    "print('Time: ', stop - start, 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b37db4",
   "metadata": {},
   "source": [
    "### 2.3. Model II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44608e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train CNN using clean labels\n",
    "imgs_train_2, imgs_test_2, labels_train, labels_test  = train_test_split(imgs[2000:10000], clean_labels[2000:], test_size=0.2, random_state=1)\n",
    "imgs_train_2, imgs_valid_2, labels_train, labels_valid  = train_test_split(imgs_train_2, labels_train, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbcf868a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize x\n",
    "X_train_2 = np.array(imgs_train_2) / 255\n",
    "X_valid_2 = np.array(imgs_valid_2) / 255\n",
    "X_test_2 = np.array(imgs_test_2) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a43fcb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_II(image):\n",
    "    '''\n",
    "    This function should takes in the image of dimension 32*32*3 as input and returns a label prediction\n",
    "    '''\n",
    "    #create model\n",
    "    model = Sequential()\n",
    "    #add model layers\n",
    "    model.add(Conv2D(32, (3,3), padding=\"same\", activation=\"relu\", input_shape=(32, 32, 3)))\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    model.add(Conv2D(64, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    model.add(Conv2D(64, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(Dense(10))\n",
    "    #compile model using accuracy to measure model performance\n",
    "    model.compile(optimizer='adam', loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "    #train the model\n",
    "    history = model.fit(X_train_2, labels_train, epochs=10, validation_data=(X_valid_2, labels_valid))\n",
    "    #predict\n",
    "    X_test = np.array(image)/255\n",
    "    return np.round(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3896933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "150/150 [==============================] - 7s 43ms/step - loss: 1.9796 - accuracy: 0.2667 - val_loss: 1.7412 - val_accuracy: 0.3650\n",
      "Epoch 2/10\n",
      "150/150 [==============================] - 6s 41ms/step - loss: 1.6034 - accuracy: 0.4110 - val_loss: 1.5547 - val_accuracy: 0.4219\n",
      "Epoch 3/10\n",
      "150/150 [==============================] - 6s 41ms/step - loss: 1.4688 - accuracy: 0.4650 - val_loss: 1.4238 - val_accuracy: 0.4725\n",
      "Epoch 4/10\n",
      "150/150 [==============================] - 6s 41ms/step - loss: 1.3267 - accuracy: 0.5271 - val_loss: 1.3532 - val_accuracy: 0.5206\n",
      "Epoch 5/10\n",
      "150/150 [==============================] - 6s 41ms/step - loss: 1.1833 - accuracy: 0.5733 - val_loss: 1.3009 - val_accuracy: 0.5344\n",
      "Epoch 6/10\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 1.0826 - accuracy: 0.6033 - val_loss: 1.3452 - val_accuracy: 0.5163\n",
      "Epoch 7/10\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.9354 - accuracy: 0.6606 - val_loss: 1.2677 - val_accuracy: 0.5594\n",
      "Epoch 8/10\n",
      "150/150 [==============================] - 6s 41ms/step - loss: 0.7957 - accuracy: 0.7125 - val_loss: 1.3034 - val_accuracy: 0.5412\n",
      "Epoch 9/10\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.6834 - accuracy: 0.7573 - val_loss: 1.3843 - val_accuracy: 0.5406\n",
      "Epoch 10/10\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.5359 - accuracy: 0.8131 - val_loss: 1.5267 - val_accuracy: 0.5256\n",
      "Time:  64.32693 seconds\n"
     ]
    }
   ],
   "source": [
    "# test (less than 1 min)\n",
    "start = timeit.default_timer()\n",
    "history = model_II(imgs_test_2)\n",
    "stop = timeit.default_timer()\n",
    "print('Time: ', stop - start, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c89eaab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "150/150 [==============================] - 7s 42ms/step - loss: 2.0810 - accuracy: 0.2308 - val_loss: 1.8219 - val_accuracy: 0.3269\n",
      "Epoch 2/10\n",
      "150/150 [==============================] - 7s 43ms/step - loss: 1.6962 - accuracy: 0.3781 - val_loss: 1.7614 - val_accuracy: 0.3675\n",
      "Epoch 3/10\n",
      "150/150 [==============================] - 6s 41ms/step - loss: 1.5387 - accuracy: 0.4519 - val_loss: 1.5109 - val_accuracy: 0.4431\n",
      "Epoch 4/10\n",
      "150/150 [==============================] - 6s 41ms/step - loss: 1.4094 - accuracy: 0.4956 - val_loss: 1.4325 - val_accuracy: 0.4706\n",
      "Epoch 5/10\n",
      "150/150 [==============================] - 6s 41ms/step - loss: 1.2737 - accuracy: 0.5515 - val_loss: 1.3587 - val_accuracy: 0.4981\n",
      "Epoch 6/10\n",
      "150/150 [==============================] - 7s 50ms/step - loss: 1.1676 - accuracy: 0.5721 - val_loss: 1.3238 - val_accuracy: 0.5025\n",
      "Epoch 7/10\n",
      "150/150 [==============================] - 6s 43ms/step - loss: 1.0435 - accuracy: 0.6279 - val_loss: 1.3054 - val_accuracy: 0.5394\n",
      "Epoch 8/10\n",
      "150/150 [==============================] - 6s 43ms/step - loss: 0.9352 - accuracy: 0.6581 - val_loss: 1.3141 - val_accuracy: 0.5469\n",
      "Epoch 9/10\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.8158 - accuracy: 0.7063 - val_loss: 1.3311 - val_accuracy: 0.5369\n",
      "Epoch 10/10\n",
      "150/150 [==============================] - 6s 42ms/step - loss: 0.6836 - accuracy: 0.7633 - val_loss: 1.3975 - val_accuracy: 0.5356\n"
     ]
    }
   ],
   "source": [
    "noisy_x = imgs[10000:].reshape(-1, 32,32,3)\n",
    "noisy_x = np.array(noisy_x) / 255\n",
    "\n",
    "x_label = np.argmax(model_II(noisy_x), axis=1)\n",
    "new_labels = np.append(clean_labels[2000:],x_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4aeed70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train & test datasets splits\n",
    "x_train, x_test, y_train, y_test  = train_test_split(imgs[2000:], new_labels, test_size = 0.2, shuffle = False)\n",
    "x_train, x_valid, y_train, y_valid  = train_test_split(x_train, y_train, test_size=0.25, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2c0023d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize x\n",
    "x_train = np.array(x_train) / 255\n",
    "x_valid = np.array(x_valid) / 255\n",
    "x_test = np.array(x_test) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb5ce421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_III(image):\n",
    "    '''\n",
    "    This function should takes in the image of dimension 32*32*3 as input and returns a label prediction\n",
    "    '''\n",
    "    #create model\n",
    "    model = Sequential()\n",
    "    #add model layers\n",
    "    model.add(Conv2D(32, (3,3), padding=\"same\", activation=\"relu\", input_shape=(32, 32, 3)))\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    model.add(Conv2D(64, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    model.add(Conv2D(64, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(Dense(10))\n",
    "    #compile model using accuracy to measure model performance\n",
    "    model.compile(optimizer='adam', loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "    #train the model\n",
    "    history = model.fit(x_train, y_train, epochs=10, validation_data=(x_valid, y_valid))\n",
    "    #predict\n",
    "    X_test = np.array(image)/255\n",
    "    return np.round(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1f2e89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "900/900 [==============================] - 36s 40ms/step - loss: 0.8692 - accuracy: 0.8135 - val_loss: 0.8500 - val_accuracy: 0.8102\n",
      "Epoch 2/10\n",
      "900/900 [==============================] - 38s 42ms/step - loss: 0.7796 - accuracy: 0.8142 - val_loss: 0.7946 - val_accuracy: 0.8102\n",
      "Epoch 3/10\n",
      "900/900 [==============================] - 38s 42ms/step - loss: 0.7418 - accuracy: 0.8140 - val_loss: 0.7631 - val_accuracy: 0.8102\n",
      "Epoch 4/10\n",
      "900/900 [==============================] - 38s 42ms/step - loss: 0.7110 - accuracy: 0.8140 - val_loss: 0.7372 - val_accuracy: 0.8099\n",
      "Epoch 5/10\n",
      "900/900 [==============================] - 38s 42ms/step - loss: 0.6869 - accuracy: 0.8137 - val_loss: 0.7506 - val_accuracy: 0.8091\n",
      "Epoch 6/10\n",
      "900/900 [==============================] - 38s 43ms/step - loss: 0.6551 - accuracy: 0.8132 - val_loss: 0.7502 - val_accuracy: 0.8089\n",
      "Epoch 7/10\n",
      "900/900 [==============================] - 38s 43ms/step - loss: 0.6212 - accuracy: 0.8138 - val_loss: 0.7474 - val_accuracy: 0.8087\n",
      "Epoch 8/10\n",
      "900/900 [==============================] - 40s 44ms/step - loss: 0.5869 - accuracy: 0.8169 - val_loss: 0.7569 - val_accuracy: 0.7925\n",
      "Epoch 9/10\n",
      "900/900 [==============================] - 38s 43ms/step - loss: 0.5418 - accuracy: 0.8209 - val_loss: 0.7671 - val_accuracy: 0.7968\n",
      "Epoch 10/10\n",
      "900/900 [==============================] - 39s 44ms/step - loss: 0.4884 - accuracy: 0.8316 - val_loss: 0.8224 - val_accuracy: 0.7821\n",
      "Time:  386.06937640000024 seconds\n"
     ]
    }
   ],
   "source": [
    "# test (less than 1 min)\n",
    "start = timeit.default_timer()\n",
    "history = model_III(x_test)\n",
    "stop = timeit.default_timer()\n",
    "print('Time: ', stop - start, 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d82f5be",
   "metadata": {},
   "source": [
    "## 3. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d46ec73",
   "metadata": {},
   "source": [
    "For assessment, we will evaluate your final model on a hidden test dataset with clean labels by the `evaluation` function defined as follows. Although you will not have the access to the test set, the function would be useful for the model developments. For example, you can split the small training set, using one portion for weakly supervised learning and the other for validation purpose. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3066abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [DO NOT MODIFY THIS CELL]\n",
    "def evaluation(model, test_labels, test_imgs):\n",
    "    y_true = test_labels\n",
    "    y_pred = []\n",
    "    for image in test_imgs:\n",
    "        y_pred.append(model(image))\n",
    "    print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "622e10cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "../data/test_labels.csv not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_59932/1258430874.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Nonetheless, you can create your own validation set to run the evlauation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mn_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtest_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenfromtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../data/test_labels.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"int8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mtest_imgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mgenfromtxt\u001b[1;34m(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise, max_rows, encoding, like)\u001b[0m\n\u001b[0;32m   1789\u001b[0m             \u001b[0mfname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1790\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1791\u001b[1;33m             \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1792\u001b[0m             \u001b[0mfid_ctx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclosing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1793\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\numpy\\lib\\_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m     \u001b[0mds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\numpy\\lib\\_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[0;32m    529\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[0;32m    530\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s not found.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: ../data/test_labels.csv not found."
     ]
    }
   ],
   "source": [
    "# [DO NOT MODIFY THIS CELL]\n",
    "# This is the code for evaluating the prediction performance on a testset\n",
    "# You will get an error if running this cell, as you do not have the testset\n",
    "# Nonetheless, you can create your own validation set to run the evlauation\n",
    "n_test = 10000\n",
    "test_labels = np.genfromtxt('../data/test_labels.csv', delimiter=',', dtype=\"int8\")\n",
    "test_imgs = np.empty((n_test,32,32,3))\n",
    "for i in range(n_test):\n",
    "    img_fn = f'../data/test_images/test{i+1:05d}.png'\n",
    "    test_imgs[i,:,:,:]=cv2.cvtColor(cv2.imread(img_fn),cv2.COLOR_BGR2RGB)\n",
    "evaluation(baseline_model, test_labels, test_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a84fc0",
   "metadata": {},
   "source": [
    "The overall accuracy is $0.24$, which is better than random guess (which should have a accuracy around $0.10$). For the project, you should try to improve the performance by the following strategies:\n",
    "\n",
    "- Consider a better choice of model architectures, hyperparameters, or training scheme for the predictive model;\n",
    "- Use both `clean_noisy_trainset` and `noisy_trainset` for model training via **weakly supervised learning** methods. One possible solution is to train a \"label-correction\" model using the former, correct the labels in the latter, and train the final predictive model using the corrected dataset.\n",
    "- Apply techniques such as $k$-fold cross validation to avoid overfitting;\n",
    "- Any other reasonable strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa0d4203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "900/900 [==============================] - 37s 41ms/step - loss: 0.8850 - accuracy: 0.8135 - val_loss: 0.8495 - val_accuracy: 0.8102\n",
      "Epoch 2/10\n",
      "900/900 [==============================] - 40s 44ms/step - loss: 0.7922 - accuracy: 0.8142 - val_loss: 0.7979 - val_accuracy: 0.8102\n",
      "Epoch 3/10\n",
      "900/900 [==============================] - 42s 46ms/step - loss: 0.7487 - accuracy: 0.8142 - val_loss: 0.7677 - val_accuracy: 0.8102\n",
      "Epoch 4/10\n",
      "805/900 [=========================>....] - ETA: 3s - loss: 0.7206 - accuracy: 0.8142"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9020/120501310.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mevaluation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_III\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclean_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimgs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9020/3663023221.py\u001b[0m in \u001b[0;36mevaluation\u001b[1;34m(model, test_labels, test_imgs)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_imgs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9020/2201305724.py\u001b[0m in \u001b[0;36mmodel_III\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparseCategoricalCrossentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrom_logits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;31m#train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[1;31m#predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                 _r=1):\n\u001b[0;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "evaluation(model_III, clean_labels[0:2000], imgs[0:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1732a75f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
